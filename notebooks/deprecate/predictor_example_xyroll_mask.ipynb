{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e8f896c",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/nye0/SAM-Med2D/blob/main/predictor_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaeee30",
   "metadata": {
    "id": "c0b71431"
   },
   "source": [
    "## Environment Set-up\n",
    "edit from [sam colab](https://colab.research.google.com/github/facebookresearch/segment-anything/blob/main/notebooks/automatic_mask_generator_example.ipynb#scrollTo=MTeAdX_mHwAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8843337a",
   "metadata": {
    "id": "47e5a78f"
   },
   "source": [
    "\n",
    "\n",
    "If you're running this notebook locally using Jupyter, please clone `SAM-Med2D` into a directory named `SAM_Med2D`. Note that you do **not** need to install `segment_anything` in your local environment, as `SAM-Med2D` and `SAM` share function names that could lead to conflicts.\n",
    "\n",
    "For Google Colab users: Set `using_colab=True` in the cell below before executing it. Although you can select 'GPU' under 'Edit' -> 'Notebook Settings' -> 'Hardware Accelerator', this notebook is designed to run efficiently in a CPU environment as well.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28d8964",
   "metadata": {
    "id": "b4a4b25c"
   },
   "source": [
    "# SAM-Med2D generates predicted object masks based on prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5a6d3c",
   "metadata": {
    "id": "69b28288"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6e2dc5",
   "metadata": {
    "id": "29bc90d5"
   },
   "outputs": [],
   "source": [
    "def show_mask(mask, ax, random_color=False):\n",
    "    if random_color:\n",
    "        color = np.array([0, 1, 0, 0.5])\n",
    "    else:\n",
    "        color = np.array([1, 0, 0, 0.5])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "\n",
    "def show_points(coords, labels, ax, marker_size=100):\n",
    "    pos_points = coords[labels==1]\n",
    "    neg_points = coords[labels==0]\n",
    "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='.', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='.', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "\n",
    "def show_box(box, ax):\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f86efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "from skimage.measure import label, regionprops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2afeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(slce, predict_mask, gt, points, labels, fn):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(slce, cmap='gray')\n",
    "    show_mask(gt, plt.gca(), random_color=True)\n",
    "    show_mask(predict_mask, plt.gca())\n",
    "    show_points(points, labels, plt.gca())\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    # plt.savefig(f\"output/{fn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693d0f2a-083b-4245-9cc7-7c414bed75c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(slce, predict_mask, gt, box, fn):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(slce, cmap='gray')\n",
    "    # show_mask(gt, plt.gca(), random_color=True)\n",
    "    show_mask(predict_mask, plt.gca())\n",
    "    # show_box(box, plt.gca())\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    # plt.savefig(f\"output/{fn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1c8e64",
   "metadata": {
    "id": "23842fb2"
   },
   "source": [
    "## Example image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e751e1",
   "metadata": {
    "id": "98b228b8"
   },
   "source": [
    "## Load SAM-Med2D model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea82425",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7e28150b",
    "outputId": "265f718c-79a0-4a6e-b1fe-759b21f20d94"
   },
   "outputs": [],
   "source": [
    "from segment_anything import sam_model_registry\n",
    "from segment_anything.predictor_sammed import SammedPredictor\n",
    "from argparse import Namespace\n",
    "args = Namespace()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "args.image_size = 256\n",
    "args.encoder_adapter = True\n",
    "args.sam_checkpoint = \"sam-med2d_b.pth\"\n",
    "model = sam_model_registry[\"vit_b\"](args).to(device)\n",
    "predictor = SammedPredictor(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195e779b",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "args.image_size = 1024\n",
    "args.encoder_adapter = False\n",
    "args.sam_checkpoint = \"/volume/willy-dev/sota/SAM-Med2D/sam_vit_b_01ec64.pth\"\n",
    "model2 = sam_model_registry[\"vit_b\"](args).to(device)\n",
    "predictor2 = SammedPredictor(model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e52b0c",
   "metadata": {
    "id": "c925e829"
   },
   "source": [
    "Process the image to produce an image embedding by calling `SammedPredictor.set_image`. `SammedPredictor` remembers this embedding and will use it for subsequent mask prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f73460a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04191020-e17d-4cee-a275-4c69cb6dc590",
   "metadata": {},
   "outputs": [],
   "source": [
    "glob.glob('/volume/open-dataset-ssd/ai99/gen_data/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c978e905-02dd-45c4-9943-575b00cfdce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_slce(slce):\n",
    "    if torch.is_tensor(slce):\n",
    "        slce = slce.cpu().numpy()\n",
    "    slce -= slce.min()\n",
    "    slce /= slce.max()\n",
    "    slce *= 255\n",
    "    slce = slce.astype(np.uint8)\n",
    "    slce = np.stack([slce, slce, slce], axis=2)\n",
    "    return slce\n",
    "\n",
    "def get_side_pred(predictor, pred, img, gt, rot_point, centroid, offset):\n",
    "\n",
    "    slce = norm_slce(rot_img[:, int(rot_point[1])])\n",
    "    \n",
    "    predictor.set_image(slce)\n",
    "    input_point = [[int(rot_point[0]), centroid[0]]]\n",
    "    input_label = [1]\n",
    "\n",
    "    proj = torch.nonzero(gt[centroid[0], int(rot_point[1])])\n",
    "    if proj.shape[0] > 0:\n",
    "\n",
    "        proj_min, proj_max = proj.min().cpu().numpy(), proj.max().cpu().numpy()\n",
    "        input_point += [[proj_min+5, centroid[0]], [proj_max-5, centroid[0]]]\n",
    "        input_label += [1, 1]\n",
    "        \n",
    "    input_point = np.array(input_point)\n",
    "    input_label = np.array(input_label)\n",
    "\n",
    "    masks, scores, logits = predictor.predict(\n",
    "                    point_coords=input_point,\n",
    "                    point_labels=input_label,\n",
    "                    multimask_output=True,\n",
    "                )\n",
    "    \n",
    "    # visualize(slce, masks[0], gt[:, int(rot_point[1])].cpu().numpy(), input_point, input_label, f\"{offset}.png\")\n",
    "\n",
    "    z = int(rot_point[1])\n",
    "\n",
    "    pred[:, [z-1, z, z+1]] = torch.tensor(masks[0]).unsqueeze(1).repeat(1, 3, 1).cuda()\n",
    "\n",
    "    return pred\n",
    "\n",
    "import math\n",
    "from torchvision.transforms.functional import rotate, InterpolationMode\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def rotate_(origin, point, angle):\n",
    "    \"\"\"\n",
    "    Rotate a point counterclockwise by a given angle around a given origin.\n",
    "\n",
    "    The angle should be given in radians.\n",
    "    \"\"\"\n",
    "    ox, oy = origin\n",
    "    px, py = point\n",
    "\n",
    "    qx = ox + math.cos(angle) * (px - ox) - math.sin(angle) * (py - oy)\n",
    "    qy = oy + math.sin(angle) * (px - ox) + math.cos(angle) * (py - oy)\n",
    "    return qx, qy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022b5af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dices = []\n",
    "dicesb = []\n",
    "dicesc = []\n",
    "mms = []\n",
    "mmms = []\n",
    "\n",
    "for di in tqdm(glob.glob('/volume/open-dataset-ssd/ai99/gen_data/meningioma/*')):\n",
    "\n",
    "    try:\n",
    "        img = sitk.ReadImage(f'{di}/axc.nii.gz')\n",
    "        img = sitk.GetArrayFromImage(img)\n",
    "\n",
    "        mask = sitk.ReadImage(f'{di}/seg.nii.gz')\n",
    "        mask = sitk.GetArrayFromImage(mask)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    if img.shape[0] < 100:\n",
    "        continue\n",
    "\n",
    "    mask = label(mask)\n",
    "\n",
    "    for i, prop in enumerate(regionprops(mask)):\n",
    "        \n",
    "        if prop.area == 0:\n",
    "            continue\n",
    "            \n",
    "        centroid = np.array(prop.centroid).astype(int)\n",
    "        \n",
    "        rot_img = torch.tensor(img.astype(float)).cuda()\n",
    "        rot_mask = torch.tensor(mask.astype(float)).cuda()\n",
    "        rot_pred = torch.zeros_like(rot_img).float().cuda()\n",
    "\n",
    "        rot_pred[centroid[0]] = rot_mask[centroid[0]]\n",
    "        \n",
    "        zx_img = rot_img.permute(1, 0, 2).contiguous()\n",
    "        zx_mask = rot_mask.permute(1, 0, 2).contiguous()\n",
    "        zx_pred = rot_pred.permute(1, 0, 2).contiguous()\n",
    "\n",
    "        long_length = max(zx_img.shape[1:])\n",
    "\n",
    "        pad_h1 = (long_length - zx_img.shape[1])//2\n",
    "        pad_h2 = long_length - zx_img.shape[1] - pad_h1\n",
    "\n",
    "        pad_w1 = (long_length - zx_img.shape[2])//2\n",
    "        pad_w2 = long_length - zx_img.shape[2] - pad_w1\n",
    "\n",
    "        zx_img = F.pad(zx_img, (pad_w2, pad_w1, pad_h2, pad_h1))\n",
    "        zx_pred = F.pad(zx_pred, (pad_w2, pad_w1, pad_h2, pad_h1))\n",
    "        zx_mask = F.pad(zx_mask, (pad_w2, pad_w1, pad_h2, pad_h1))\n",
    "\n",
    "        degree = math.atan(img.shape[0]/img.shape[1]) / 0.0174533\n",
    "        zx_img = rotate(zx_img, degree, interpolation=InterpolationMode.BILINEAR)\n",
    "        zx_pred = rotate(zx_pred, degree)\n",
    "        zx_mask = rotate(zx_mask, degree)\n",
    "\n",
    "        zx_img = zx_img.permute(1, 0, 2).contiguous()\n",
    "        zx_mask = zx_mask.permute(1, 0, 2).contiguous()\n",
    "        zx_pred = zx_pred.permute(1, 0, 2).contiguous()\n",
    "\n",
    "        dices_tp, dices_pred = 0, 0\n",
    "\n",
    "        for z in zx_pred.nonzero()[:,0].unique():\n",
    "\n",
    "            tar_img = zx_img[z].clone()\n",
    "            tar_mask = zx_mask[z].clone()\n",
    "            tar_pred = zx_pred[z].clone()\n",
    "\n",
    "            tar_img[tar_img < 1] = 0\n",
    "            crop_min_x, crop_min_y = tar_img.nonzero().min(0)[0]\n",
    "            crop_max_x, crop_max_y = tar_img.nonzero().max(0)[0]\n",
    "    \n",
    "            tar_img = tar_img[crop_min_x:crop_max_x, crop_min_y:crop_max_y]\n",
    "            tar_mask = tar_mask[crop_min_x:crop_max_x, crop_min_y:crop_max_y]\n",
    "            tar_pred = tar_pred[crop_min_x:crop_max_x, crop_min_y:crop_max_y]\n",
    "\n",
    "            zx_pred_nonzero = tar_pred.nonzero()\n",
    "\n",
    "            if zx_pred_nonzero.shape[0] < 5: continue\n",
    "\n",
    "            input_point, input_label = [], []\n",
    "\n",
    "            # print(zx_pred_nonzero)\n",
    "\n",
    "            point_a = zx_pred_nonzero.shape[0]//2\n",
    "            point_b = int(zx_pred_nonzero.shape[0] * 0.25)\n",
    "            point_c = int(zx_pred_nonzero.shape[0] * 0.75)\n",
    "            input_point = zx_pred_nonzero[[point_a, point_b, point_c]][:, [1, 0]].cpu().numpy()\n",
    "            input_label = [1, 1, 1]\n",
    "\n",
    "            input_point = np.array(input_point)\n",
    "            input_label = np.array(input_label)\n",
    "\n",
    "            slce = norm_slce(tar_img)\n",
    "            predictor2.set_image(slce)\n",
    "            masks, scores, logits = predictor2.predict(\n",
    "                            point_coords=input_point,\n",
    "                            point_labels=input_label,\n",
    "                            multimask_output=False,\n",
    "                        )\n",
    "\n",
    "            visualize(slce, masks[0], tar_mask.cpu().numpy(), input_point, input_label, \"\")\n",
    "\n",
    "            dices_tp += (tar_mask.cpu().numpy()*masks[0]).sum()\n",
    "            dices_pred += masks[0].sum()\n",
    "\n",
    "            dice = 2 * ((tar_mask.cpu().numpy()*masks[0]).sum() + 1e-5)/(tar_mask.cpu().numpy().sum() + masks[0].sum() + 1e-5)\n",
    "            dicesc.append(dice)\n",
    "\n",
    "        dicesb_ = 2 * dices_tp / (dices_pred + prop.area)\n",
    "        dicesb.append(dicesb_)\n",
    "        \n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881f21f2-06c5-47f9-a67d-465964ce917c",
   "metadata": {},
   "outputs": [],
   "source": [
    "math.atan(img.shape[0]/img.shape[1])/0.0174533 * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc18b458-6f68-4c36-ac7b-a0e83eafcdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc86b3a-94c4-454a-926c-e2ebeb0aa070",
   "metadata": {},
   "outputs": [],
   "source": [
    "zx_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a432989b-4df4-4005-94fb-e2d35673e7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e917e39-ee24-4ab2-a0fa-b5c61a3fff19",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('tmp_dicesb.npy', dicesb)\n",
    "np.save('tmp_dicesc.npy', dicesc)\n",
    "np.save('tmp_mms.npy', mms)\n",
    "np.save('tmp_mmms.npy', mmms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b63d394",
   "metadata": {},
   "outputs": [],
   "source": [
    "dices = np.array(dices)\n",
    "dicesb = np.array(dicesb)\n",
    "dicesc = np.array(dicesc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe51618",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(dicesb))\n",
    "plt.hist(dicesb,bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948226d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(dicesc))\n",
    "plt.hist(dicesc, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7f7abf-6601-489a-a934-e6a5d24c7a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "dicesc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e925264",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(dices)[np.array(mms) > 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401c81a3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 767
    },
    "id": "a91ba973",
    "outputId": "31a15693-8167-4e84-f95c-5c489c25cce7"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(slce)\n",
    "show_points(input_point, input_label, plt.gca())\n",
    "plt.axis('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a6f4d1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 739
    },
    "id": "e9c227a6",
    "outputId": "5f5c2bcb-e629-4dcb-8eef-efd50896164f"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(slce)\n",
    "show_mask(masks, plt.gca())\n",
    "show_points(input_point, input_label, plt.gca())\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a845d6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 739
    },
    "id": "e9c227a6",
    "outputId": "5f5c2bcb-e629-4dcb-8eef-efd50896164f"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(slce)\n",
    "show_mask(gt, plt.gca())\n",
    "show_points(input_point, input_label, plt.gca())\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c480ec20",
   "metadata": {
    "id": "ca1afd77"
   },
   "source": [
    "## Optimizing Segmentation Results by Point Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fe34ee",
   "metadata": {
    "id": "89b557a5"
   },
   "outputs": [],
   "source": [
    "input_point1 = np.array([[169, 140]])\n",
    "input_label1 = np.array([0])\n",
    "input_points = np.concatenate((input_point, input_point1))\n",
    "input_labels = np.concatenate((input_label, input_label1))\n",
    "mask_inputs = torch.sigmoid(torch.as_tensor(logits, dtype=torch.float, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c73dbfc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7948f44a",
    "outputId": "25d0b67a-8fd9-4140-9f98-3235caad04db"
   },
   "outputs": [],
   "source": [
    "masks, scores, logits = predictor.predict(\n",
    "    point_coords=input_points,\n",
    "    point_labels=input_labels,\n",
    "    mask_input = mask_inputs,\n",
    "    multimask_output=True,\n",
    ")\n",
    "masks.shape  # (number_of_masks) x H x W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744db172",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 739
    },
    "id": "ea7cbc82",
    "outputId": "b22a46f5-66ef-4522-b742-4fff0ca14051"
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(image)\n",
    "show_mask(masks, plt.gca())\n",
    "show_points(input_points, input_labels, plt.gca())\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442d2098",
   "metadata": {
    "id": "41e2d5a9"
   },
   "source": [
    "## Specifying a specific object with a bounding box"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21a8834",
   "metadata": {
    "id": "d61ca7ac"
   },
   "source": [
    "The model can also take a box as input, provided in xyxy format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbd3b31",
   "metadata": {
    "id": "8ea92a7b"
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('data_demo/images/s0114_111.png')\n",
    "predictor.set_image(image)\n",
    "input_box = np.array([89,43,113,64]) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349ee456",
   "metadata": {
    "id": "b35a8814"
   },
   "outputs": [],
   "source": [
    "masks, _, _ = predictor.predict(\n",
    "    point_coords=None,\n",
    "    point_labels=None,\n",
    "    box=input_box,\n",
    "    multimask_output=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7136de94",
   "metadata": {
    "id": "984b79c1",
    "outputId": "14dbc495-5b2d-42d3-ac24-464051550f37"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(image)\n",
    "show_mask(masks[0], plt.gca())\n",
    "show_box(input_box, plt.gca())\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37b4df7-abe9-4cf1-9a74-126f911fa8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93a4975",
   "metadata": {
    "id": "c1ed9f0a"
   },
   "source": [
    "## Multiple bounding box prediction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0df494f",
   "metadata": {
    "id": "0a06681b"
   },
   "outputs": [],
   "source": [
    "input_boxes = torch.tensor([[72,110,136,143],[124,92,160,132]], device=predictor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f02bc89",
   "metadata": {
    "id": "117521a3",
    "outputId": "a8f52676-d5fd-4845-f1c8-9cd3d8f6a01a"
   },
   "outputs": [],
   "source": [
    "transformed_boxes = predictor.apply_boxes_torch(input_boxes, image.shape[:2], (args.image_size, args.image_size))\n",
    "masks, _, _ = predictor.predict_torch(\n",
    "    point_coords=None,\n",
    "    point_labels=None,\n",
    "    boxes=transformed_boxes,\n",
    "    multimask_output=True,\n",
    ")\n",
    "print(transformed_boxes.shape)\n",
    "print(masks.shape)  # (batch_size) x (num_predicted_masks_per_input) x H x W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155fda57",
   "metadata": {
    "id": "c00c3681",
    "outputId": "a10ba1bc-dd89-4213-a6d1-93611e8f55a5"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(image)\n",
    "for mask in masks:\n",
    "    show_mask(mask.cpu().numpy(), plt.gca(), random_color=True)\n",
    "for box in input_boxes:\n",
    "    show_box(box.cpu().numpy(), plt.gca())\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
